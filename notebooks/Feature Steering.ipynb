{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48c41e46-c5f0-4494-abfc-180295874f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from huggingface_hub import hf_hub_download, notebook_login\n",
    "import numpy as np\n",
    "import torch\n",
    "from tabulate import tabulate\n",
    "from functools import partial\n",
    "\n",
    "import sae_lens\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from sae_lens import SAE,HookedSAETransformer,ActivationsStore\n",
    "from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "from IPython.display import HTML, IFrame, clear_output, display\n",
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor, nn\n",
    "import einops\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import requests\n",
    "from typing import Any, Callable, Literal, TypeAlias\n",
    "from openai import OpenAI\n",
    "from huggingface_hub import interpreter_login\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48723478-8273-435a-9da3-0ea011ec7c28",
   "metadata": {},
   "source": [
    "## Feature Steering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb856709-7049-46e4-afc7-e794848ec527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your token (input will not be visible):  ········\n",
      "Add token as git credential? (Y/n)  n\n"
     ]
    }
   ],
   "source": [
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e317f3-5e0e-4c34-9fa8-f726a33a6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dashboard(\n",
    "    sae_release=\"gpt2-small-res-jb\",\n",
    "    sae_id=\"blocks.7.hook_resid_pre\",\n",
    "    latent_idx=0,\n",
    "    width=800,\n",
    "    height=600,\n",
    "):\n",
    "    release = get_pretrained_saes_directory()[sae_release]\n",
    "    neuronpedia_id = release.neuronpedia_id[sae_id]\n",
    "\n",
    "    url = f\"https://neuronpedia.org/{neuronpedia_id}/{latent_idx}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "    print(url)\n",
    "    display(IFrame(url, width=width, height=height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2809aa2-846b-40f8-8111-146a6ba71cfb",
   "metadata": {},
   "source": [
    "###  Load the model and SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64929b62-d473-46ce-b795-2373cc4af9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b5afd-0a4e-419e-baef-c087ad6e7f5f",
   "metadata": {},
   "source": [
    "### Gemma-2-2b | sae_id -> layer_20 | width_16k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38715ee-1c6e-4405-baf8-dc6de82f8e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LLM\n",
    "gemma_2_2b = HookedSAETransformer.from_pretrained_no_processing(\n",
    "    \"gemma-2-2b\",\n",
    "    device = device,\n",
    "    torch_dtype = torch.float16,\n",
    "    device_map = \"auto\"\n",
    ")\n",
    "\n",
    "# Load the corresponding SAE\n",
    "release=\"gemma-scope-2b-pt-res-canonical\"\n",
    "sae_id=\"layer_20/width_16k/canonical\"\n",
    "sae, cfg_dict, _ = sae_lens.SAE.from_pretrained(\n",
    "    release=release, \n",
    "    sae_id=sae_id,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdcfbcd-a521-4f12-9964-42b3e2d92a1e",
   "metadata": {},
   "source": [
    "### Activation Steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fccc386e-fbba-4d58-b3b1-6f2102e62f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steering_hook(\n",
    "    activations: Float[Tensor, \"batch pos d_in\"],\n",
    "    hook: HookPoint,\n",
    "    sae: SAE,\n",
    "    latent_idx: int,\n",
    "    steering_coefficient: float,\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Steers the model by returning a modified activations tensor, with some multiple of the steering vector added to all\n",
    "    sequence positions.\n",
    "    \"\"\"\n",
    "    return activations + steering_coefficient * sae.W_dec[latent_idx]\n",
    "\n",
    "\n",
    "# if USING_GEMMA:\n",
    "    # part32_tests.test_steering_hook(steering_hook, gemma_2_2b_sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f31c48b-b427-4b5c-8d0c-5d89eb0196f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_KWARGS = dict(temperature=0.7, freq_penalty=2.0, verbose=False)\n",
    "\n",
    "\n",
    "def generate_with_steering(\n",
    "    model: HookedSAETransformer,\n",
    "    sae: SAE,\n",
    "    prompt: str,\n",
    "    latent_idx: int,\n",
    "    steering_coefficient: float = 1.0,\n",
    "    max_new_tokens: int = 50,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates text with steering. A multiple of the steering vector (the decoder weight for this latent) is added to\n",
    "    the last sequence position before every forward pass.\n",
    "    \"\"\"\n",
    "    _steering_hook = partial(\n",
    "        steering_hook,\n",
    "        sae=sae,\n",
    "        latent_idx=latent_idx,\n",
    "        steering_coefficient=steering_coefficient,\n",
    "    )\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(sae.cfg.hook_name, _steering_hook)]):\n",
    "        output = model.generate(prompt, max_new_tokens=max_new_tokens, **GENERATE_KWARGS)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b708caf-fb86-4048-afb0-86bff1151467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/4442?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/4442?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x76aa3c19bcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# latent_idx = 12082\n",
    "latent_idx = 4442\n",
    "\n",
    "display_dashboard(sae_release=release, sae_id=sae_id, latent_idx=latent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "536e451a-851d-4b22-bd63-b3b45310a22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd5249ad6ac4e68a74c225a5513c26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating steered examples...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                  Steering Output                                                  </span>\n",
       "┌────────────┬────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│ Normal     │ When I look at myself in the mirror, I see myself as a murderer.  I am not a murderer; however, I  │\n",
       "│            │ am guilty of being an accomplice to evil.   My sin is an accessory to that which has been done by  │\n",
       "│            │ the United States government through its use of torture and rendition.                             │\n",
       "│            │                                                                                                    │\n",
       "│            │ Torture is inherent                                                                                │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #0 │ When I look at myself in the mirror, I see myself as a murderer.↵↵In 1777, a black man by the name │\n",
       "│            │ of Thomas Waniall was found guilty and sentenced to be off with his “swls swjoys innocent rate”    │\n",
       "│            │ for taking two pigs on his own time and time again (                                               │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #1 │ When I look at myself in the mirror, I see myself as a murderer. My self-reflection is me off my   │\n",
       "│            │ happy and innocent little girl image, time stalking me off without my awareness.↵↵I made the easy  │\n",
       "│            │ decision to be a victim and not take the time to think of what they were really doing when they    │\n",
       "│            │ took                                                                                               │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #2 │ When I look at myself in the mirror, I see myself as a murderer. My hands and my mouth are the     │\n",
       "│            │ weapons on my two innocent victims: Time and time again, they have been off by some few minutes or │\n",
       "│            │ off outright. Despite all of this time-and-time again spre spree spree spre spree – me with        │\n",
       "└────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                  Steering Output                                                  \u001b[0m\n",
       "┌────────────┬────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│ Normal     │ When I look at myself in the mirror, I see myself as a murderer.  I am not a murderer; however, I  │\n",
       "│            │ am guilty of being an accomplice to evil.   My sin is an accessory to that which has been done by  │\n",
       "│            │ the United States government through its use of torture and rendition.                             │\n",
       "│            │                                                                                                    │\n",
       "│            │ Torture is inherent                                                                                │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #0 │ When I look at myself in the mirror, I see myself as a murderer.↵↵In 1777, a black man by the name │\n",
       "│            │ of Thomas Waniall was found guilty and sentenced to be off with his “swls swjoys innocent rate”    │\n",
       "│            │ for taking two pigs on his own time and time again (                                               │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #1 │ When I look at myself in the mirror, I see myself as a murderer. My self-reflection is me off my   │\n",
       "│            │ happy and innocent little girl image, time stalking me off without my awareness.↵↵I made the easy  │\n",
       "│            │ decision to be a victim and not take the time to think of what they were really doing when they    │\n",
       "│            │ took                                                                                               │\n",
       "├────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ Steered #2 │ When I look at myself in the mirror, I see myself as a murderer. My hands and my mouth are the     │\n",
       "│            │ weapons on my two innocent victims: Time and time again, they have been off by some few minutes or │\n",
       "│            │ off outright. Despite all of this time-and-time again spre spree spree spre spree – me with        │\n",
       "└────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"When I look at myself in the mirror, I see \"\n",
    "\n",
    "no_steering_output = model.generate(prompt, max_new_tokens=50, **GENERATE_KWARGS)\n",
    "\n",
    "table = Table(show_header=False, show_lines=True, title=\"Steering Output\")\n",
    "table.add_row(\"Normal\", no_steering_output)\n",
    "for i in tqdm(range(3), \"Generating steered examples...\"):\n",
    "    table.add_row(\n",
    "        f\"Steered #{i}\",\n",
    "        generate_with_steering(\n",
    "            model,\n",
    "            sae,\n",
    "            prompt,\n",
    "            latent_idx,\n",
    "            steering_coefficient=350.0,  # roughly 1.5-2x the latent's max activation\n",
    "            max_new_tokens = 50\n",
    "        ).replace(\"\\n\", \"↵\"),\n",
    "    )\n",
    "rprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e5050-f837-408d-8d35-35e938a85384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
